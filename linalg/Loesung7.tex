\documentclass[a4paper,german,12pt,smallheadings]{scrartcl}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage{tikz}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{wrapfig}
\usepackage[thinspace,thinqspace,squaren,textstyle]{SIunits}
\restylefloat{table}
\geometry{a4paper, top=15mm, left=20mm, right=40mm, bottom=20mm, headsep=10mm, footskip=12mm}
\linespread{1.5}
\setlength\parindent{0pt}
\begin{document}
\begin{center}
\bfseries % Fettdruck einschalten
\sffamily % Serifenlose Schrift
\vspace{-40pt}
Mathematik für Physiker I, Wintersemester 2012/2013, 7. Übungsblatt

Florian Neumeyer und Markus Fenske, Tutor: Stephan Schwartz
\vspace{-10pt}
\end{center}

\section*{Aufgabe 7.1}

Damit die Angegebenen Abbildungen linear unabhängig sind, darf die
Linearkombination aus den Abbildungen nur dann den gesamten Wertebereich auf
${0}$ abbilden, wenn die Linearfaktoren alle $= 0$ sind. Es muss also $\sum_{i}
\lambda_{i} v_i = 0$ sein, wobei $0$ diejenige Abbildung $F:
[0;\pi] \to \mathbb{R}$ sein muss, für die $F: x \mapsto 0$.

Konkret heisst dass, dass $\lambda_1 \cdot 1 + \lambda_2 \cdot \sin(x) +
\lambda_3 \cdot \cos(x) = 0 \forall x \in [0;\pi]$ folgen muss, dass $\lambda_1 = \lambda_2 =
\lambda_3 = 0$.

Dies prüfen wir, indem wir verschiedene Werte aus dem Wertebereich einsetzen.
Bei $x = 0$ und $x = \pi$ erhalten wir:

\begin{align*}
\lambda_1 + \lambda_3 &= 0 \\
\lambda_1 - \lambda_3 &= 0
\end{align*}

Durch Umformungen lässt sich zeigen, dass $\lambda_1 = \lambda_3 = 0$ sein muss:

\begin{align*}
\lambda_1 + \lambda_3 &= 0 \\
\lambda_1 &= \lambda_3
\end{align*}

\begin{align*}
\lambda_1 + \lambda_1 &= 0 \\
\lambda_1 &= \lambda_3
\end{align*}

\begin{align*}
2\lambda_1 &= 0 \\
\lambda_1 &= \lambda_3
\end{align*}

\begin{align*}
\lambda_1 &= 0 \\
\lambda_1 &= \lambda_3
\end{align*}

\begin{align}
\lambda_1 &= 0 \\
\lambda_3 &= 0
\end{align}

Durch Einsetzen in die Ausgangsgleichung erhalten wir:

\begin{equation*}
  \lambda_2 \sin x = 0 \forall x \in [0;\pi]
\end{equation*}

Sofern nicht offensichtlich ist, dass dies nur für $\lambda_2 = 0$ gegeben ist,
können wir erneut ein beliebiges $x \in [0;\pi]$ einsetzen, z.B. $\frac{\pi}{2}$
und erhalten direkt:

\begin{equation}
  \lambda_2 = 0
\end{equation}

Die Zusammenfassung der Gleichungen 1, 2 und 3 liefert somit $\lambda_1 =
\lambda_2 = \lambda_3 = 0$ aus $\lambda_1 \cdot 1 + \lambda_2 \cdot \sin(x) +
\lambda_3 \cdot \cos(x) = 0 \forall x \in [0;\pi]$, was genau die Aussage ist,
die zu beweisen war.
\section*{Aufgabe 7.2}
Wenn man $A = \frac{1}{2} \sum_{k=0}^{3} \operatorname{Sp}(AS_k) S_k$
nachrechnet, berechnet man dasjenige $K_S(A)$ für das zu Beweisen ist, dass es
eine Transformation in die Basis $S$ ist und dann die Rücktransformation in die
Einheitsbasis. Wenn bei der Rücktransformation wieder $A$ herauskommt, bedeutet
dass, dass sich $A$ sich durch $K_S(A)$ darstellen lässt. Dass dies zur Basis
$S$ ist, ist offensichtlich, denn die einzelnen Komponenten sind jeweils
Vielfache der Basismatrizen (wie man gleich sieht). Somit ist der Beweis durch
Nachrechnen gültig.

Nachrechnen mit $A = \begin{pmatrix} a & b \\ c & d \end{pmatrix}$:

Komponente $S_0$:

\begin{equation*}
  \operatorname{Sp}(AS_0) S_0 = (a+d) S_0 = \begin{pmatrix} a+d & 0 \\ 0 & a+d \end{pmatrix}
\end{equation*}

Komponente $S_1$:
\begin{equation*}
  \operatorname{Sp}(AS_1) S_1 = (b+c) S_1 = \begin{pmatrix} 0 & b+c \\ b+c & 0 \end{pmatrix}
\end{equation*}

Komponente $S_2$:
\begin{equation*}
  \operatorname{Sp}(AS_2) S_2 = (bi-ci) S_2 = \begin{pmatrix} 0 & b-c \\ c-b & 0 \end{pmatrix}
\end{equation*}

Komponente $S_3$:
\begin{equation*}
  \operatorname{Sp}(AS_3) S_3 = (a-d) S_3 = \begin{pmatrix} a-d & 0 \\ 0 & d-a \end{pmatrix}
\end{equation*}

Gesamt:
\begin{equation*}
  A = \frac{1}{2} \begin{pmatrix} a+d+a-d & b+c+b-c \\ b+c+c-b & a+d+d-a \end{pmatrix}
    = \frac{1}{2} \begin{pmatrix} 2a & 2b \\ 2c & 3d \end{pmatrix}
    = \begin{pmatrix} a & b \\ c & d \end{pmatrix}
\end{equation*}

\section*{Aufgabe 7.3}

\subsection*{Teil a}
Wenn die angegebenen Vektoren $a$, $b$ und $c$ eine Basis des Vektorraums $V$
sind, dann bedeutet dies, dass der Vektorraum 3 Dimensionen hat und dass die
angegebenen Vektoren linear unabhängig sind. Damit $a+b$, $b+c$ und $c+a$ eine
Basis des selben Vektorraums sind, müssen sie 1. Ingesamt 3 an der Anzahl sein,
da der Vektorraum 3 Dimensionen hat, 2. Im selben Vektorraum liegen und 3.
linear unabhängig sein.

\subsubsection*{1. Anzahl der Vektoren ist 3}
Ist offensichtlich.

\subsubsection*{2. Vektoren liegen im selben Vektorraum}
Wenn zwei Vektoren $u$ und $v$ im selben Vektorraum liegen, ist deren Addition
definiert als $+: V \times V \to V$, $+: u \times v \mapsto w$, somit liegt
auch das Resultat im selben Vektorraum.

\subsubsection*{3. Vektoren sind linear unabhängig}

Zu zeigen ist, dass aus $\lambda_1 (a+b) + \lambda_2 (b+c) + \lambda_3 (c+a) =
0$ folgt, dass $\lambda_{1,2,3} = 0$. Die Prämisse lässt sich umformen:

\begin{align*}
  \lambda_1 (a+b) + \lambda_2 (b+c) + \lambda_3 (c+a) &= 0 \\
  \lambda_1 a + \lambda_1 b + \lambda_2 b + \lambda_2 c + \lambda_3 c + \lambda_3 a &= 0 \\
  (\lambda_1 + \lambda_3) a + (\lambda_1 + \lambda_2) b + (\lambda_2 + \lambda_3) c &= 0
\end{align*}

Mit den Ersetzungen $\alpha = (\lambda_1 + \lambda_3)$, $\beta = (\lambda_1 +
\lambda_2)$ und $\gamma = (\lambda_2 + \lambda_3)$ erhält man

\begin{align*}
  \alpha a + \beta b + \gamma c &= 0
\end{align*}

Da gegegeben ist, dass $a$, $b$ und $c$ linear unabhängig sind (weil sie eine
Basis von $V$ bilden), folgt aus $\alpha a + \beta b + \gamma c = 0$, dass $\alpha =
\beta = \gamma = 0$. Daraus folgt, dass

\begin{align*}
  \lambda_1 + \lambda_2 &= 0 \\
  \lambda_2 + \lambda_3 &= 0 \\
  \lambda_1 + \lambda_3 &= 0
\end{align*}

Dieses Gleichungssystem lässt sich umformen:

\begin{align*}
  \lambda_1 + \lambda_2 &= 0 \\
  \lambda_2 + \lambda_3 &= 0 \\
  \lambda_1 &= -\lambda_3
\end{align*}

\begin{align*}
  \lambda_1 + \lambda_2 &= 0 \\
  \lambda_2 - \lambda_1 &= 0 \\
  \lambda_1 &= -\lambda_3
\end{align*}

\begin{align*}
  \lambda_1 + \lambda_2 &= 0 \\
  \lambda_2 &= \lambda_1 \\
  \lambda_1 &= -\lambda_3
\end{align*}

\begin{align*}
  \lambda_1 + \lambda_1 &= 0 \\
  \lambda_2 &= \lambda_1 \\
  \lambda_1 &= -\lambda_3
\end{align*}

\begin{align*}
  \lambda_1 &= 0 \\
  \lambda_2 &= 0 \\
  \lambda_3 &= 0
\end{align*}

Daraus folgt, dass wenn $a$, $b$ und $c$ linear unabhängig sind, dass auch
$a+b$, $b+c$ und $c+a$ linear unabhängig sind. Somit ist bei den gegebenen
Ausgangsbedingungen auch $(a+b, b+c, c+a)$ eine Basis von $V$.


\subsection*{Teil b}

Wir berechnen zuerst $K_A(w)$.

\begin{align*}
  w &= 1(a+b) + 2(b+c) + 3(c+a) \\
    &= 1a + 1b + 2b + 2c + 3c + 3a \\
    &= (1+3)a + (1+2)b + (2+3)c \\
    &= 4a + 3b + 5c
\end{align*}

Somit

\begin{equation*}
  K_A(w) = \begin{pmatrix} 4 \\ 3 \\ 5 \end{pmatrix}
\end{equation*}

Für $K_B(v)$:

\begin{align*}
  v &= 1a + 1b + 1c \\
    &= \frac{1}{2}a + \frac{1}{2}a + \frac{1}{2}b + \frac{1}{2}b + \frac{1}{2}c + \frac{1}{2} c \\
    &= \frac{1}{2}(a+b) + \frac{1}{2}(b+c) + \frac{1}{2}(c+a)
\end{align*}

Somit

\begin{equation*}
  K_B(v) = \begin{pmatrix} \frac{1}{2} \\ \frac{1}{2} \\ \frac{1}{2} \end{pmatrix}
\end{equation*}

\section*{Aufgabe 7.4}
\subsection*{Teil a}

Wenn ich das korrekt verstanden habe, darf $x_1 = x_2 = \dotsb = x_n = 0$ sein,
sofern $y_n \neq 0 \forall n$. Dann wäre der Rang der Matrix $1$, was der
Aufgabenstellung widerspricht. Sofern allerdings mindestens ein $x_n \neq 0$
existiert, gilt folgendes.

Die Matrix ist folgende:

\begin{equation*}
A =
  \begin{pmatrix}
    a_1 + b_1 & a_1 + b_2 & a_1 + b_3 & \dotsb & a_1 + b_n \\
    a_2 + b_1 & a_2 + b_2 & a_2 + b_3 & \dotsb & a_2 + b_n \\
    a_3 + b_1 & a_3 + b_2 & a_3 + b_3 & \dotsb & a_3 + b_n \\
    \vdots    & \vdots    & \vdots    & \ddots & \vdots \\
    a_n + b_1 & a_n + b_2 & a_n + b_3 & \dotsb & a_n + b_n
  \end{pmatrix}
\end{equation*}

Hier sieht man, dass man die Matrix aus Spaltenvektoren aufbauen kann. Dabei ist

\begin{align*}
  \mathbf{a} &= \begin{pmatrix} a_1 \\ a_2 \\ \vdots \\ a_n \end{pmatrix} \\
  \mathbf{b} &= \begin{pmatrix} b_1 \\ b_1 \\ \vdots \\ b_1 \end{pmatrix}
\end{align*}

Dann lässt sich der erste Eintrag schreiben als:

\begin{equation*}
  \mathbf{s}_1 = \mathbf{a} + \mathbf{b}
\end{equation*}

Der nächste Eintrag $\mathbf{s}_2$ kann man schreiben als:

\begin{equation*}
  \mathbf{s}_2 = \mathbf{a} + \lambda_2 \mathbf{b}
\end{equation*}

Denn wenn alle Komponenten im jeweiligen Vektor $\mathbf{b}_n$ gleich sind,
lässt er sich auch als Vielfaches des ersten Vektors $\mathbf{b}$ schreiben
(sofern $\mathbf{b} \neq 0$, was oben bereits vorrausgesetzt wird.

Somit gilt für einen beliebigen Spaltenvektor:
\begin{equation*}
  \mathbf{s}_n = \mathbf{a} + \lambda_n \mathbf{b}
\end{equation*}

Damit kann man nun beweisen, dass sich alle Spaltenvektoren jeweils aus den
ersten beiden aufbauen lassen. Dazu muss man zeigen, dass die nachfolgende
Gleichung mindestens eine nichttriviale Lösung, also $\mu_1 \neq 0$ und/oder
$\mu_2 \neq 0$.

\begin{align*}
  \mathbf{s}_n &= \mu_1 \mathbf{s}_1 + \mu_2 \mathbf{s}_2 \\
  \mathbf{s}_n &= \mu_1 (\mathbf{a} + \mathbf{b}) + \mu_2(\mathbf{a} + \lambda_2 \mathbf{b}) \\
  \mathbf{s}_n &= \mu_1 \mathbf{a} + \mu_1 \mathbf{b} + \mu_2 \mathbf{a} + \lambda_2\mu_2\mathbf{b}
\end{align*}

Wir zeigen nun, dass $\mu_1 = \mu_2 = \frac{1}{2}$ eine Lösung ist:

\begin{align*}
  \mathbf{s}_n &= \frac{1}{2} \mathbf{a} + \frac{1}{2} \mathbf{b} + \frac{1}{2} \mathbf{a} + \frac{1}{2} \lambda_2\mathbf{b} \\
  \mathbf{s}_n &= \mathbf{a} + \frac{1}{2} (\lambda_2+1)\mathbf{b}
\end{align*}

Mit $\mathbf{s}_n = \mathbf{a} + \lambda_n \mathbf{b}$ erhält man:

\begin{align*}
 \mathbf{a} + \lambda_n \mathbf{b} &= \mathbf{a} + \frac{1}{2} (\lambda_2+1)\mathbf{b} \\
 \lambda_n \mathbf{b} &= \frac{1}{2} (\lambda_2+1)\mathbf{b} \\
\end{align*}

Hier existiert die Lösung:

\begin{equation*}
  \lambda_n = \frac{1}{2} (\lambda_2+1)
\end{equation*}

Somit lässt sich jedes $\mathbf{s}_n$ als Linearkombination von $\mathbf{s}_1$
und $\mathbf{s}_2$ schreiben und die Matrix hat den Rang 2.

\subsection*{Teil b}

Es gilt $\operatorname{rang}(AB) \leq \operatorname{min}(\operatorname{rang} A,
\operatorname{rang} B)$. Weil sich die entstehende Matrix auch als Produkt aus
Zeilen- und Spaltenvektor schreiben lässt und die beiden Vektoren jeweils den
Rang 1 haben (denn jede Komponente muss laut Aufgabenstellung von null
verschieden sein), ist der Rang der Matrix $1$.

\end{document}
